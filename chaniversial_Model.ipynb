{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06b3c99-4037-4c85-9fe7-f71e100aa667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a8b3a4-8c36-465d-94f3-17adae8a9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895c4626-3f2f-4b51-8a64-059ff833d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "import os, random\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9025f9f9-345f-4bd0-8d2e-45e484dec045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ichanho/workspace/dogs-vs-cats'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50f8a3d8-c491-4592-9e1c-525a3f4639ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500 12500\n"
     ]
    }
   ],
   "source": [
    "cat_list = glob(current_path + \"/train/cat**\", recursive=True)\n",
    "dog_list = glob(current_path + \"/train/dog**\", recursive=True)\n",
    "print(len(cat_list), len(dog_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b25c56-828c-4465-bce5-4936429f09e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ichanho/workspace/dogs-vs-cats/train/cat.8971.jpg /home/ichanho/workspace/dogs-vs-cats/train/cat.10606.jpg\n"
     ]
    }
   ],
   "source": [
    "print(cat_list[0], cat_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a87d1bd-6329-4044-b0f5-4949ca157b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ichanho/workspace/dogs-vs-cats/train/dog.365.jpg /home/ichanho/workspace/dogs-vs-cats/train/dog.11395.jpg\n"
     ]
    }
   ],
   "source": [
    "print(dog_list[0], dog_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48d91699-7efc-4d6b-ac4b-efe952b8ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 200\n",
    "IMAGE_HEIGHT = 200\n",
    "IMAGE_CHANNEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "debf3d9b-b2ce-4026-b8ce-3fc1cff02319",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_valid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96adafc1-381a-41d1-a7e9-887bcc6ead02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing the cat image (resizing the image)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:21<00:00, 152.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing the dog image (resizing the image)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:24<00:00, 147.66it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"processing the cat image (resizing the image)\")\n",
    "for i in tqdm(cat_list):\n",
    "    img = Image.open(i)\n",
    "    img = img.convert(\"RGB\")\n",
    "    resized = img.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    img_numpy = np.array(resized)\n",
    "    x_train.append(img_numpy)\n",
    "    x_valid.append(0)\n",
    "    \n",
    "print(\"processing the dog image (resizing the image)\")\n",
    "for i in tqdm(dog_list):\n",
    "    img = Image.open(i)\n",
    "    img = img.convert(\"RGB\")\n",
    "    resized = img.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    img_numpy = np.array(resized)\n",
    "    x_train.append(img_numpy)\n",
    "    x_valid.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beba3417-216a-4b47-a8af-33cc268270fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 200, 200, 3)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(x_train)\n",
    "Y = pd.get_dummies(x_valid)\n",
    "Y = np.array(Y)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ee41280-5786-487a-971b-dfab79710187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "748919a9-7821-464a-a704-c9c7f28f282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st\n",
    "model.add(Conv2D(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL), kernel_size=(3, 3), filters=32, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86e729d7-24c6-4b9b-be56-dd3bf7a86754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd\n",
    "model.add(Conv2D(kernel_size=(3,3),filters=64, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f6d9655-8834-4e00-a38b-b6ebed18f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd\n",
    "model.add(Conv2D(kernel_size=(3,3),filters=128, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acece132-6249-426f-8eca-260c7f9c5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a483a3-06d8-4e99-b2bb-6aea3aa1dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('Adam', 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3993ba36-1361-4b4a-853b-eec193bf5a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 198, 198, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 97, 97, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 46, 46, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               34669056  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 34,766,274\n",
      "Trainable params: 34,764,802\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e180ae4-cb9e-4831-b2ee-4ab2255801bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 1.3572 - val_accuracy: 0.7346\n",
      "Epoch 2/25\n",
      "625/625 [==============================] - 83s 133ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.8344 - val_accuracy: 0.8236\n",
      "Epoch 3/25\n",
      "625/625 [==============================] - 83s 133ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 1.2176 - val_accuracy: 0.7580\n",
      "Epoch 4/25\n",
      "625/625 [==============================] - 83s 132ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 1.0036 - val_accuracy: 0.7892\n",
      "Epoch 5/25\n",
      "625/625 [==============================] - 83s 132ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.5635 - val_accuracy: 0.8522\n",
      "Epoch 6/25\n",
      "625/625 [==============================] - 83s 132ms/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 2.0862 - val_accuracy: 0.6202\n",
      "Epoch 7/25\n",
      "625/625 [==============================] - 83s 132ms/step - loss: 0.0167 - accuracy: 0.9937 - val_loss: 1.6118 - val_accuracy: 0.7526\n",
      "Epoch 8/25\n",
      "625/625 [==============================] - 83s 132ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 1.1814 - val_accuracy: 0.7744\n",
      "Epoch 9/25\n",
      "625/625 [==============================] - 83s 132ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 1.0875 - val_accuracy: 0.7628\n",
      "Epoch 10/25\n",
      "625/625 [==============================] - 83s 132ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 1.1758 - val_accuracy: 0.7782\n",
      "Epoch 11/25\n",
      "625/625 [==============================] - 83s 132ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.9984 - val_accuracy: 0.7980\n",
      "Epoch 12/25\n",
      "412/625 [==================>...........] - ETA: 26s - loss: 0.0377 - accuracy: 0.9864"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=25, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed2345-d748-4c14-9b82-05cf6de10a62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
